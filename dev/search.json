[{"path":[]},{"path":"https://hubverse-org.github.io/hubData/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying standards acceptable behavior. Enforcement responsibility Code Conduct Committee, take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Instances abusive, harassing, otherwise unacceptable behavior may reported member Code Conduct Committee. complaints reviewed investigated promptly fairly. Code Conduct Committee use Enforcement Manual determining consequences action deem violation Code Conduct. community leaders Code Conduct Committee members obligated respect privacy security reporter incident.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to hubData","title":"Contributing to hubData","text":"outlines propose change hubData. general info contributing , hubverse packages, please see hubverse community page. can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to hubData","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed). procedures contributing bigger changes, code particular, generally follow advised tidyverse dev team, including following tidyverse style guide code recording user facing changes NEWS.md.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to hubData","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"hubverse-org/hubData\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Follow pull request checklist create Git branch pull request (PR). recommend using usethis::pr_init(\"name/brief-description/issue\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first heading—usually labelled “development version”). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to hubData","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to hubData","text":"Please note hubData project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Consortium Infectious Disease Modeling Hubs Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"structure-of-hubverse-datasets","dir":"Articles","previous_headings":"","what":"Structure of hubverse datasets","title":"Accessing data from a hub","text":"data returned connecting querying hubs can read validated model_out_tbl foundational S3 class hubverse ecosystem. model_out_tbl long-form tibble designed conform hubverse data specifications model output data. short, columns valid model_out_tbl containing model output data hub : model_id: unique character identifier model. output_type: character variable defines type representation model output given row. output_type_id: variable specifies additional identifying information specific output type given row, e.g., numeric quantile level, string giving name possible category discrete outcome, index sample. value: numeric variable provides information model’s prediction. ... : columns present depending modeling tasks defined individual modeling hub. columns referred hubverse terminology task-ID variables. hubverse tools, designed data validation, ensemble building, visualization, etc…, designed “promises” implicit data format specified model_out_tbl. example, hubEnsembles::linear_pool() function accepts input returns output model_out_tbl objects.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"hub-connections","dir":"Articles","previous_headings":"","what":"Hub connections","title":"Accessing data from a hub","text":"two functions connecting model-output data: connect_hub() used connecting fully configured hubs (.e. contain valid admin.json tasks.json hub-config directory). function uses configurations defined config files hub-config/ directory allows connecting hubs files multiple file formats (allowable formats specified file_format property admin.json). connect_model_output() allows connecting directly contents model-output directory useful connecting appropriately organised files informal hub (.e. fully configured appropriate hub-config/ files.) functions establish connections arrow package, specifically opening datasets FileSystemDatasets, one file format. functions also able connect files stored locally cloud (e.g. AWS S3 buckets). multiple file formats accepted single Hub, file format specific FileSystemDatasets combined single UnionDataset single point access entire Hub model-output dataset. applies connect_hub() fully configured Hubs, config files can used determine unifying schema across file formats. contrast, connect_model_output() can used open single file format datasets format defined explicitly file_format argument.","code":"library(hubData) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union"},{"path":[]},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"connecting-to-a-local-hub","dir":"Articles","previous_headings":"Connecting to a configured hub","what":"Connecting to a local hub","title":"Accessing data from a hub","text":"connect local hub, supply path hub connect_hub()","code":"hub_path <- system.file(\"testhubs/flusight\", package = \"hubUtils\") hub_con <- hubData::connect_hub(hub_path) hub_con #>  #> ── <hub_connection/UnionDataset> ── #>  #> • hub_name: \"US CDC FluSight\" #> • hub_path: /home/runner/work/_temp/Library/hubUtils/testhubs/flusight #> • file_format: \"csv(5/5)\", \"parquet(2/2)\", and \"arrow(1/1)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/flusight/forecasts\" #> • config_admin: hub-config/admin.json #> • config_tasks: hub-config/tasks.json #>  #> ── Connection schema #> hub_connection #> 8 columns #> forecast_date: date32[day] #> horizon: int32 #> target: string #> location: string #> output_type: string #> output_type_id: string #> value: double #> model_id: string"},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"connecting-to-a-hub-in-the-cloud","dir":"Articles","previous_headings":"Connecting to a configured hub","what":"Connecting to a hub in the cloud","title":"Accessing data from a hub","text":"connect hub cloud, first use one re-exported arrow helpers s3_bucket() gs_bucket() depending cloud storage provider, string bucket name/path create appropriate cloud *FileSystem object (details consult arrow article Using cloud storage (S3, GCS)). supply resulting *FileSystem object connect_hub().","code":"hub_path_cloud <- hubData::s3_bucket(\"hubverse/hubutils/testhubs/simple/\") hub_con_cloud <- hubData::connect_hub(hub_path_cloud) #> ℹ Updating superseded URL `Infectious-Disease-Modeling-hubs` to `hubverse-org` #> ℹ Updating superseded URL `Infectious-Disease-Modeling-hubs` to `hubverse-org` hub_con_cloud #>  #> ── <hub_connection/UnionDataset> ── #>  #> • hub_name: \"Simple Forecast Hub\" #> • hub_path: hubverse/hubutils/testhubs/simple/ #> • file_format: \"csv(3/3)\" and \"parquet(1/1)\" #> • checks: TRUE #> • file_system: \"S3FileSystem\" #> • model_output_dir: \"model-output/\" #> • config_admin: hub-config/admin.json #> • config_tasks: hub-config/tasks.json #>  #> ── Connection schema #> hub_connection #> 9 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> output_type: string #> output_type_id: double #> value: int32 #> model_id: string #> age_group: string"},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"performance-considerations","dir":"Articles","previous_headings":"Connecting to a configured hub > Connecting to a hub in the cloud","what":"Performance considerations","title":"Accessing data from a hub","text":"default, connect_hub() ignore invalid files hub’s model output directory creates connection. check prevents errors working data, negatively impacts performance. cloud-based hub uses single file type model output data, can improve performance using skip_checks argument. argument bypass default behavior scanning hub’s model output directory invalid files connecting. Using argument fail unless hub meets following criteria: model output directory contains model output data (README.md, example) model output files use single file format.","code":"hub_path_cloud <- hubData::s3_bucket(\"hubverse/hubutils/testhubs/parquet/\") hub_con_cloud <- hubData::connect_hub(hub_path_cloud, file_format = \"parquet\", skip_checks = TRUE) #> ℹ Updating superseded URL `Infectious-Disease-Modeling-hubs` to `hubverse-org` #> ℹ Updating superseded URL `Infectious-Disease-Modeling-hubs` to `hubverse-org` hub_con_cloud #>  #> ── <hub_connection/FileSystemDataset> ── #>  #> • hub_name: \"Simple Forecast Hub\" #> • hub_path: hubverse/hubutils/testhubs/parquet/ #> • file_format: \"parquet(4/4)\" #> • checks: FALSE #> • file_system: \"S3FileSystem\" #> • model_output_dir: \"model-output/\" #> • config_admin: hub-config/admin.json #> • config_tasks: hub-config/tasks.json #>  #> ── Connection schema #> hub_connection with 4 Parquet files #> 9 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> age_group: string #> output_type: string #> output_type_id: double #> value: int32 #> model_id: string"},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"accessing-data","dir":"Articles","previous_headings":"","what":"Accessing data","title":"Accessing data from a hub","text":"access data hub connection can use dplyr verbs construct querying pipelines. perform queries, can use dplyr’s collect() function: Note however example, output contains required model_id, output_type, output_type_id value columns model_out_tbl object, returned tbl_df tibble object order columns standardised.","code":"hub_con %>%   dplyr::filter(output_type == \"quantile\", location == \"US\") %>%   dplyr::collect() #> # A tibble: 276 × 8 #>    forecast_date horizon target        location output_type output_type_id value #>    <date>          <int> <chr>         <chr>    <chr>       <chr>          <dbl> #>  1 2023-05-01          1 wk ahead inc… US       quantile    0.01               0 #>  2 2023-05-01          1 wk ahead inc… US       quantile    0.025              0 #>  3 2023-05-01          1 wk ahead inc… US       quantile    0.05               0 #>  4 2023-05-01          1 wk ahead inc… US       quantile    0.1              193 #>  5 2023-05-01          1 wk ahead inc… US       quantile    0.15             495 #>  6 2023-05-01          1 wk ahead inc… US       quantile    0.2              618 #>  7 2023-05-01          1 wk ahead inc… US       quantile    0.25             717 #>  8 2023-05-01          1 wk ahead inc… US       quantile    0.3              774 #>  9 2023-05-01          1 wk ahead inc… US       quantile    0.35             822 #> 10 2023-05-01          1 wk ahead inc… US       quantile    0.4              857 #> # ℹ 266 more rows #> # ℹ 1 more variable: model_id <chr>"},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"use-collect_hub-to-return-model_out_tbls","dir":"Articles","previous_headings":"Accessing data","what":"Use collect_hub() to return model_out_tbls","title":"Accessing data from a hub","text":"Conveniently, can use hubData wrapper collect_hub() converts output dplyr::collect() model_out_tbl class object possible:","code":"tbl <- hub_con %>%   dplyr::filter(output_type == \"quantile\", location == \"US\") %>%   hubData::collect_hub()  tbl #> # A tibble: 276 × 8 #>    model_id     forecast_date horizon target location output_type output_type_id #>  * <chr>        <date>          <int> <chr>  <chr>    <chr>       <chr>          #>  1 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.01           #>  2 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.025          #>  3 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.05           #>  4 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.1            #>  5 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.15           #>  6 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.2            #>  7 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.25           #>  8 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.3            #>  9 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.35           #> 10 hub-baseline 2023-04-24          1 wk ah… US       quantile    0.4            #> # ℹ 266 more rows #> # ℹ 1 more variable: value <dbl>  class(tbl) #> [1] \"model_out_tbl\" \"tbl_df\"        \"tbl\"           \"data.frame\""},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"accessing-data-from-cloud-hubs","dir":"Articles","previous_headings":"Accessing data","what":"Accessing data from cloud hubs","title":"Accessing data from a hub","text":"Accessing data hubs cloud exactly :","code":"hub_con_cloud %>%   dplyr::filter(output_type == \"quantile\", location == \"US\") %>%   hubData::collect_hub() #> # A tibble: 230 × 9 #>    model_id     origin_date target        horizon location age_group output_type #>  * <chr>        <date>      <chr>           <int> <chr>    <chr>     <chr>       #>  1 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #>  2 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #>  3 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #>  4 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #>  5 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #>  6 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #>  7 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #>  8 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #>  9 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #> 10 hub-baseline 2022-10-08  wk inc flu h…       1 US       NA        quantile    #> # ℹ 220 more rows #> # ℹ 2 more variables: output_type_id <dbl>, value <int>"},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"limitations-of-dplyr-queries-on-arrow-datasets","dir":"Articles","previous_headings":"Accessing data","what":"Limitations of dplyr queries on arrow datasets","title":"Accessing data from a hub","text":"Note dplyr filtering options available arrow datasets. example, wanted get quantile predictions last forecast date hub, might try: doesn’t work however arrow equivalent max method Date[32] data types. situation, collect applying first filtering level work arrow finish filtering -memory data returned collect. Alternatively, depending size data, might quicker filter data two steps: get last forecast date available filtered subset. use last forecast date filtering query.","code":"hub_con %>%   dplyr::filter(     output_type == \"quantile\", location == \"US\",     forecast_date == max(forecast_date, na.rm = TRUE)   ) %>%   hubData::collect_hub() #> Error in `forecast_date == max(forecast_date, na.rm = TRUE)`: #> ! Expression not supported in filter() in Arrow #> → Call collect() first to pull data into R. hub_con %>%   dplyr::filter(output_type == \"quantile\", location == \"US\") %>%   hubData::collect_hub() %>%   dplyr::filter(forecast_date == max(forecast_date)) #> # A tibble: 92 × 8 #>    model_id     forecast_date horizon target location output_type output_type_id #>    <chr>        <date>          <int> <chr>  <chr>    <chr>       <chr>          #>  1 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.01           #>  2 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.025          #>  3 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.05           #>  4 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.1            #>  5 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.15           #>  6 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.2            #>  7 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.25           #>  8 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.3            #>  9 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.35           #> 10 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.4            #> # ℹ 82 more rows #> # ℹ 1 more variable: value <dbl> last_forecast <- hub_con %>%   dplyr::filter(output_type == \"quantile\", location == \"US\") %>%   dplyr::pull(forecast_date, as_vector = TRUE) %>%   max(na.rm = TRUE)   hub_con %>%   dplyr::filter(     output_type == \"quantile\", location == \"US\",     forecast_date == last_forecast   ) %>%   hubData::collect_hub() #> # A tibble: 92 × 8 #>    model_id     forecast_date horizon target location output_type output_type_id #>  * <chr>        <date>          <int> <chr>  <chr>    <chr>       <chr>          #>  1 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.01           #>  2 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.025          #>  3 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.05           #>  4 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.1            #>  5 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.15           #>  6 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.2            #>  7 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.25           #>  8 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.3            #>  9 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.35           #> 10 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.4            #> # ℹ 82 more rows #> # ℹ 1 more variable: value <dbl>"},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"use-arrowto_duckdb-to-extend-available-queries","dir":"Articles","previous_headings":"Accessing data > Limitations of dplyr queries on arrow datasets","what":"Use arrow::to_duckdb() to extend available queries","title":"Accessing data from a hub","text":"alternatively use arrow::to_duckdb() first convert dataset connection memory virtual DuckDB table. allows run queries supported DuckDB arrow, extending potential queries can run hub data collecting. details see DuckDB quacks Arrow: zero-copy data integration Apache Arrow DuckDB.","code":"hub_con %>%   arrow::to_duckdb() %>%   dplyr::filter(     output_type == \"quantile\", location == \"US\",     forecast_date == max(forecast_date, na.rm = TRUE)   ) %>%   hubData::collect_hub() #> # A tibble: 92 × 8 #>    model_id     forecast_date horizon target location output_type output_type_id #>  * <chr>        <date>          <int> <chr>  <chr>    <chr>       <chr>          #>  1 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.01           #>  2 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.025          #>  3 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.05           #>  4 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.1            #>  5 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.15           #>  6 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.2            #>  7 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.25           #>  8 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.3            #>  9 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.35           #> 10 hub-baseline 2023-05-08          1 wk ah… US       quantile    0.4            #> # ℹ 82 more rows #> # ℹ 1 more variable: value <dbl>"},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"connecting-to-a-model-output-directory","dir":"Articles","previous_headings":"","what":"Connecting to a model output directory","title":"Accessing data from a hub","text":"also option connect directly model output directory without using metadata hub config file. can useful hub fully configured yet. approach certain limitations though. example, overall unifying schema determined config files ability open_dataset() connect parse data correctly guaranteed across files. addition, single file_format dataset can opened. Accessing data follows procedure described fully configured hubs: connecting cloud model output data follows procedure described fully configured cloud hubs: Like connect_hub(), connect_model_output() optional skip_checks argument improves performance:","code":"model_output_dir <- system.file(\"testhubs/simple/model-output\", package = \"hubUtils\") mod_out_con <- hubData::connect_model_output(model_output_dir, file_format = \"csv\") mod_out_con #>  #> ── <mod_out_connection/FileSystemDataset> ── #>  #> • file_format: \"csv(3/3)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #>  #> ── Connection schema #> mod_out_connection with 3 csv files #> 8 columns #> origin_date: date32[day] #> target: string #> horizon: int64 #> location: string #> output_type: string #> output_type_id: double #> value: int64 #> model_id: string mod_out_con %>%   dplyr::filter(output_type == \"quantile\", location == \"US\") %>%   hubData::collect_hub() #> # A tibble: 138 × 8 #>    model_id origin_date target horizon location output_type output_type_id value #>  * <chr>    <date>      <chr>    <int> <chr>    <chr>                <dbl> <int> #>  1 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.01    135 #>  2 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.025   137 #>  3 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.05    139 #>  4 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.1     140 #>  5 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.15    141 #>  6 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.2     141 #>  7 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.25    142 #>  8 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.3     143 #>  9 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.35    144 #> 10 hub-bas… 2022-10-01  wk in…       1 US       quantile             0.4     145 #> # ℹ 128 more rows mod_out_dir_cloud <- hubData::s3_bucket(   \"hubverse/hubutils/testhubs/simple/model-output/\" ) mod_out_con_cloud <- hubData::connect_model_output(   mod_out_dir_cloud,   file_format = \"csv\" ) mod_out_con_cloud #>  #> ── <mod_out_connection/FileSystemDataset> ── #>  #> • file_format: \"csv(3/3)\" #> • checks: TRUE #> • file_system: \"S3FileSystem\" #> • model_output_dir: \"hubverse/hubutils/testhubs/simple/model-output/\" #>  #> ── Connection schema #> mod_out_connection with 3 csv files #> 8 columns #> origin_date: date32[day] #> target: string #> horizon: int64 #> location: string #> output_type: string #> output_type_id: double #> value: int64 #> model_id: string mod_out_dir_cloud <- hubData::s3_bucket(\"hubverse/hubutils/testhubs/parquet/model-output/\") mod_out_con_cloud <- hubData::connect_model_output(mod_out_dir_cloud, file_format = \"parquet\", skip_checks = TRUE) mod_out_con_cloud #>  #> ── <mod_out_connection/FileSystemDataset> ── #>  #> • file_format: \"parquet(4/4)\" #> • checks: FALSE #> • file_system: \"S3FileSystem\" #> • model_output_dir: \"hubverse/hubutils/testhubs/parquet/model-output/\" #>  #> ── Connection schema #> mod_out_connection with 4 Parquet files #> 9 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> output_type: string #> output_type_id: double #> value: int32 #> age_group: string #> model_id: string"},{"path":"https://hubverse-org.github.io/hubData/dev/articles/connect_hub.html","id":"providing-a-custom-schema","dir":"Articles","previous_headings":"Connecting to a model output directory","what":"Providing a custom schema","title":"Accessing data from a hub","text":"connecting model output directly, can also specify schema override default arrow schema auto-detection. can help times resolve conflicts data types across different dataset files. Using schema can however also produce new errors can sometimes hard debug. example, defining schema field output_type cast int32 data type. column output_type actually contain character type data coerced integer, connecting model output directory produces arrow error. Beware arrow errors can somewhat misleading times get non-informative error, good place start check schema matches columns data can coerced data types specified schema.","code":"library(arrow) #>  #> Attaching package: 'arrow' #> The following object is masked from 'package:utils': #>  #>     timestamp  model_output_schema <- arrow::schema(   origin_date = date32(),   target = string(),   horizon = int32(),   location = string(),   output_type = string(),   output_type_id = string(),   value = int32(),   model_id = string() )  mod_out_con <- hubData::connect_model_output(model_output_dir,   file_format = \"csv\",   schema = model_output_schema ) mod_out_con #>  #> ── <mod_out_connection/FileSystemDataset> ── #>  #> • file_format: \"csv(3/3)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #>  #> ── Connection schema #> mod_out_connection with 3 csv files #> 8 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> output_type: string #> output_type_id: string #> value: int32 #> model_id: string model_output_schema <- arrow::schema(   origin_date = date32(),   target = string(),   horizon = int32(),   location = string(),   output_type = int32(),   output_type_id = string(),   value = int32(),   model_id = string() )  mod_out_con <- hubData::connect_model_output(model_output_dir,   file_format = \"csv\",   schema = model_output_schema ) #> Error in `arrow::open_dataset()`: #> ! Invalid: No non-null segments were available for field 'model_id'; couldn't infer type"},{"path":"https://hubverse-org.github.io/hubData/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Anna Krystalli. Author, maintainer. Li Shandross. Contributor. Nicholas G. Reich. Contributor. Evan L. Ray. Contributor. Becky Sweger. Contributor. Consortium Infectious Disease Modeling Hubs. Copyright holder.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Krystalli (2025). hubData: Tools accessing working hubverse data. R package version 1.4.0.9000, https://github.com/hubverse-org/hubData.","code":"@Manual{,   title = {hubData: Tools for accessing and working with hubverse data},   author = {Anna Krystalli},   year = {2025},   note = {R package version 1.4.0.9000},   url = {https://github.com/hubverse-org/hubData}, }"},{"path":"https://hubverse-org.github.io/hubData/dev/index.html","id":"hubdata-","dir":"","previous_headings":"","what":"Tools for accessing and working with hubverse data","title":"Tools for accessing and working with hubverse data","text":"goal hubData provide tools accessing working hubverse Hub data. package part hubverse ecosystem, aims provide set tools infectious disease modeling hubs share collaborate work.","code":""},{"path":[]},{"path":"https://hubverse-org.github.io/hubData/dev/index.html","id":"latest","dir":"","previous_headings":"Installation","what":"Latest","title":"Tools for accessing and working with hubverse data","text":"can install latest version hubData R-universe:","code":"install.packages(\"hubData\", repos = c(\"https://hubverse-org.r-universe.dev\", \"https://cloud.r-project.org\"))"},{"path":"https://hubverse-org.github.io/hubData/dev/index.html","id":"development","dir":"","previous_headings":"Installation","what":"Development","title":"Tools for accessing and working with hubverse data","text":"want test new features yet released, can install development version hubData GitHub : [!NOTE] hubData dependency arrow package. troubleshooting arrow installation problems, please consult arrow package documentation. also try installing package Apache R Universe repository :","code":"# install.packages(\"remotes\") remotes::install_github(\"hubverse-org/hubData\") install.packages(\"arrow\", repos = c(\"https://apache.r-universe.dev\", \"https://cran.r-project.org\"))"},{"path":"https://hubverse-org.github.io/hubData/dev/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Tools for accessing and working with hubverse data","text":"Please note hubData package released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Tools for accessing and working with hubverse data","text":"Interested contributing back open-source Hubverse project? Learn get involved Hubverse Community contribute hubData package.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/arrow_to_r_datatypes.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapping of Arrow types to base R types — arrow_to_r_datatypes","title":"Mapping of Arrow types to base R types — arrow_to_r_datatypes","text":"named character vector mapping common arrow::Schema field types (strings) corresponding base R types. mapping used translate validate column types working Parquet files Arrow datasets, especially schema inference compatibility checks.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/arrow_to_r_datatypes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapping of Arrow types to base R types — arrow_to_r_datatypes","text":"","code":"arrow_to_r_datatypes"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/arrow_to_r_datatypes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Mapping of Arrow types to base R types — arrow_to_r_datatypes","text":"named character vector 8 entries.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/arrow_to_r_datatypes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapping of Arrow types to base R types — arrow_to_r_datatypes","text":"safest portable Arrow types supported hubverse. Types present mapping treated unsupported.","code":""},{"path":[]},{"path":"https://hubverse-org.github.io/hubData/dev/reference/as_r_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert or validate an Arrow schema for compatibility with base R column types — as_r_schema","title":"Convert or validate an Arrow schema for compatibility with base R column types — as_r_schema","text":"functions help convert validate arrow::Schema object (typically Parquet file Arrow dataset) translating Arrow types R equivalents, extracting type strings, checking compatibility.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/as_r_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert or validate an Arrow schema for compatibility with base R column types — as_r_schema","text":"","code":"as_r_schema(arrow_schema, call = rlang::caller_env())  arrow_schema_to_string(arrow_schema)  is_supported_arrow_type(arrow_schema)  validate_arrow_schema(arrow_schema, call = rlang::caller_env())"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/as_r_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert or validate an Arrow schema for compatibility with base R column types — as_r_schema","text":"arrow_schema arrow::Schema object, one returned arrow::read_parquet(..., as_data_frame = FALSE)$schema arrow::open_dataset(...)$schema. call calling environment, used error reporting validate_arrow_schema() as_r_schema() (default: caller's environment).","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/as_r_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert or validate an Arrow schema for compatibility with base R column types — as_r_schema","text":"as_r_schema(): named character vector mapping column names base R type strings (e.g., \"integer\", \"double\", \"logical\"). arrow_schema_to_string(): named character vector mapping column names Arrow type strings. is_supported_arrow_type(): named logical vector indicating whether column supported. validate_arrow_schema(): Returns original schema (invisibly) column types supported; otherwise throws error.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/as_r_schema.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert or validate an Arrow schema for compatibility with base R column types — as_r_schema","text":"as_r_schema() maps Arrow types base R types (e.g., \"int32\" → \"integer\"). throws error unsupported column types present. arrow_schema_to_string() returns named character vector raw Arrow type strings (e.g., \"int64\", \"date32[day]\") schema field. is_supported_arrow_type() returns named logical vector indicating whether schema field type supported. validate_arrow_schema() throws error fields unsupported Arrow type. full list supported types R mappings, see arrow_to_r_datatypes().","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/as_r_schema.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert or validate an Arrow schema for compatibility with base R column types — as_r_schema","text":"","code":"# Path to a single Parquet file file_path <- system.file(   \"testhubs/parquet/model-output/hub-baseline/2022-10-01-hub-baseline.parquet\",   package = \"hubUtils\" )  # Get schema from the file file_schema <- arrow::read_parquet(file_path, as_data_frame = FALSE)$schema  # Convert to R types as_r_schema(file_schema) #>    origin_date         target        horizon       location    output_type  #>         \"Date\"    \"character\"      \"integer\"    \"character\"    \"character\"  #> output_type_id          value  #>       \"double\"      \"integer\"   # Get raw Arrow type strings arrow_schema_to_string(file_schema) #>    origin_date         target        horizon       location    output_type  #>  \"date32[day]\"       \"string\"        \"int32\"       \"string\"       \"string\"  #> output_type_id          value  #>       \"double\"        \"int32\"   # Check which columns are supported is_supported_arrow_type(file_schema) #>    origin_date         target        horizon       location    output_type  #>           TRUE           TRUE           TRUE           TRUE           TRUE  #> output_type_id          value  #>           TRUE           TRUE   # Validate schema (throws error if any unsupported types are present) validate_arrow_schema(file_schema)  # From a multi-file dataset dataset_path <- system.file(   \"testhubs/parquet/model-output/hub-baseline\",   package = \"hubUtils\" ) ds <- arrow::open_dataset(dataset_path) as_r_schema(ds$schema) #>    origin_date         target        horizon       location    output_type  #>         \"Date\"    \"character\"      \"integer\"    \"character\"    \"character\"  #> output_type_id          value  #>       \"double\"      \"integer\"  arrow_schema_to_string(ds$schema) #>    origin_date         target        horizon       location    output_type  #>  \"date32[day]\"       \"string\"        \"int32\"       \"string\"       \"string\"  #> output_type_id          value  #>       \"double\"        \"int32\"  is_supported_arrow_type(ds$schema) #>    origin_date         target        horizon       location    output_type  #>           TRUE           TRUE           TRUE           TRUE           TRUE  #> output_type_id          value  #>           TRUE           TRUE  validate_arrow_schema(ds$schema)"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/coerce_to_hub_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce data.frame/tibble column data types to hub schema data types or character. — coerce_to_hub_schema","title":"Coerce data.frame/tibble column data types to hub schema data types or character. — coerce_to_hub_schema","text":"Coerce data.frame/tibble column data types hub schema data types character.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/coerce_to_hub_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce data.frame/tibble column data types to hub schema data types or character. — coerce_to_hub_schema","text":"","code":"coerce_to_hub_schema(   tbl,   config_tasks,   skip_date_coercion = FALSE,   as_arrow_table = FALSE,   output_type_id_datatype = c(\"from_config\", \"auto\", \"character\", \"double\", \"integer\",     \"logical\", \"Date\") )  coerce_to_character(tbl, as_arrow_table = FALSE)"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/coerce_to_hub_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce data.frame/tibble column data types to hub schema data types or character. — coerce_to_hub_schema","text":"tbl model output data.frame/tibble config_tasks list version content's hub's tasks.json config file created using function hubUtils::read_config(). skip_date_coercion Logical. Whether skip coercing dates. can faster, especially larger tbls. as_arrow_table Logical. Whether return arrow table. Defaults FALSE. output_type_id_datatype character string. One \"from_config\", \"auto\", \"character\", \"double\", \"integer\", \"logical\", \"Date\". Defaults \"from_config\" uses setting output_type_id_datatype property tasks.json config file available. property set config, argument falls back \"auto\" determines  output_type_id data type automatically tasks.json config file simplest data type required represent output type ID values across output types hub. point estimate output types (output_type_ids NA,) collected hub, output_type_id column assigned character data type auto-determined. data type values can used override automatic determination. Note attempting coerce output_type_id data type valid data (e.g. trying coerce\"character\" values \"double\") likely result error potentially unexpected behaviour use care.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/coerce_to_hub_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce data.frame/tibble column data types to hub schema data types or character. — coerce_to_hub_schema","text":"tbl column data types coerced hub schema data types character. as_arrow_table = TRUE, output also converted arrow table.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/coerce_to_hub_schema.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Coerce data.frame/tibble column data types to hub schema data types or character. — coerce_to_hub_schema","text":"coerce_to_hub_schema(): coerce columns hub schema data types. coerce_to_character(): coerce columns character","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_hub.html","id":null,"dir":"Reference","previous_headings":"","what":"Collect Hub model output data — collect_hub","title":"Collect Hub model output data — collect_hub","text":"collect_hub retrieves data <hub_connection>/<mod_out_connection> executing <arrow_dplyr_query> local tibble. function also attempts convert output model_out_tbl class object returning.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_hub.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collect Hub model output data — collect_hub","text":"","code":"collect_hub(x, silent = FALSE, ...)"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_hub.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collect Hub model output data — collect_hub","text":"x <hub_connection>/<mod_out_connection> <arrow_dplyr_query> object. silent Logical. Whether suppress message generated conversion model_out_tbl fails. ... argument passed as_model_out_tbl().","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_hub.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collect Hub model output data — collect_hub","text":"model_out_tbl, unless conversion model_out_tbl fails case tibble returned.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_hub.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collect Hub model output data — collect_hub","text":"","code":"hub_path <- system.file(\"testhubs/simple\", package = \"hubUtils\") hub_con <- connect_hub(hub_path) # Collect all data in a hub hub_con %>% collect_hub() #> # A tibble: 599 × 9 #>    model_id     origin_date target        horizon location age_group output_type #>  * <chr>        <date>      <chr>           <int> <chr>    <chr>     <chr>       #>  1 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        mean        #>  2 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        quantile    #>  3 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        quantile    #>  4 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        quantile    #>  5 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        quantile    #>  6 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        quantile    #>  7 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        quantile    #>  8 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        quantile    #>  9 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        quantile    #> 10 hub-baseline 2022-10-01  wk inc flu h…       1 US       NA        quantile    #> # ℹ 589 more rows #> # ℹ 2 more variables: output_type_id <dbl>, value <int> # Filter data before collecting hub_con %>%   dplyr::filter(is.na(output_type_id)) %>%   collect_hub() #> # A tibble: 1 × 9 #>   model_id     origin_date target         horizon location age_group output_type #> * <chr>        <date>      <chr>            <int> <chr>    <chr>     <chr>       #> 1 hub-baseline 2022-10-01  wk inc flu ho…       1 US       NA        mean        #> # ℹ 2 more variables: output_type_id <dbl>, value <int> # Pass arguments to as_model_out_tbl() dplyr::filter(hub_con, is.na(output_type_id)) %>%   collect_hub(remove_empty = TRUE) #> # A tibble: 1 × 8 #>   model_id  origin_date target horizon location output_type output_type_id value #> * <chr>     <date>      <chr>    <int> <chr>    <chr>                <dbl> <int> #> 1 hub-base… 2022-10-01  wk in…       1 US       mean                    NA   150"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_zoltar.html","id":null,"dir":"Reference","previous_headings":"","what":"Load forecasts from zoltardata.com in hubverse format — collect_zoltar","title":"Load forecasts from zoltardata.com in hubverse format — collect_zoltar","text":"collect_zoltar retrieves data zoltardata.com project transforms Zoltar's native download format hubverse one. Zoltar (documentation ) pre-hubverse research project implements repository model forecast results, including tools administer, query, visualize uploaded data, along R Python APIs access data programmatically (zoltr zoltpy, respectively.) (hubData function implemented using zoltr package.)","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_zoltar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load forecasts from zoltardata.com in hubverse format — collect_zoltar","text":"","code":"collect_zoltar(   project_name,   models = NULL,   timezeros = NULL,   units = NULL,   targets = NULL,   types = NULL,   as_of = NULL,   point_output_type = \"median\" )"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_zoltar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load forecasts from zoltardata.com in hubverse format — collect_zoltar","text":"project_name string naming Zoltar project load forecasts . Assumes host zoltardata.com . models character vector specifies models query. Must model abbreviations. Defaults NULL, queries models project. timezeros character vector specifies timezeros query. Must yyyy-mm-dd format. Defaults NULL, queries timezeros project. units character vector specifies units query. Must unit abbreviations. Defaults NULL, queries units project. targets character vector specifies targets query. Must target names. Defaults NULL, queries targets project. types character vector specifies forecast types query. Choices \"bin\", \"point\", \"sample\", \"quantile\", \"mean\", \"median\". Defaults NULL, queries types project. Note: Zoltar supports \"named\" \"mode\" forecasts, function ignores . as_of datetime string specifies forecast version. datetime must include timezone information disambiguation, without query fail. datatime parsing function used (base::strftime) extremely lenient comes formatting, please exercise caution. Defaults NULL load latest version. point_output_type string specifies convert zoltar point forecast data hubverse output type. Must either \"median\" \"mean\". Defaults \"median\".","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_zoltar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load forecasts from zoltardata.com in hubverse format — collect_zoltar","text":"hubverse model_out_tbl containing following columns: \"model_id\", \"timezero\", \"season\", \"unit\", \"horizon\", \"target\", \"output_type\", \"output_type_id\", \"value\".","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_zoltar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load forecasts from zoltardata.com in hubverse format — collect_zoltar","text":"Zoltar's data model differs hubverse important ways. Zoltar's model concepts unit, target, timezero, hubverse projects hub-configurable columns, makes mapping former latter imperfect. particular, Zoltar units translate roughly hubverse task IDs, Zoltar targets include target outcome numeric horizon target name, Zoltar timezeros map round ids. Finally, Zoltar's forecast types differ hubverse. Whereas Zoltar seven types (bin, named, point, sample, quantile, mean, median, mode), hubverse six (cdf, mean, median, pmf, quantile, sample), overlap. Additional notes: Requires user Zoltar account (use Zoltar contact page request one). Requires Z_USERNAME Z_PASSWORD environment vars set user's Zoltar account. Zoltar supports \"named\" \"mode\" forecasts, function ignores . Rows non-numeric values ignored. function removes numeric_horizon mentions zoltar target names. Target names can contain maximum one numeric_horizon. Example: \"1 wk ahead inc case\" -> \"wk ahead inc case\". Querying large number rows may cause errors, recommend providing one filtering arguments (e.g., models, timezeros, etc.) limit result.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/collect_zoltar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load forecasts from zoltardata.com in hubverse format — collect_zoltar","text":"","code":"if (FALSE) { # \\dontrun{ df <- collect_zoltar(\"Docs Example Project\") df <-   collect_zoltar(\"Docs Example Project\", models = c(\"docs_mod\"),                         timezeros = c(\"2011-10-16\"), units = c(\"loc1\", \"loc3\"),                         targets = c(\"pct next week\", \"cases next week\"), types = c(\"point\"),                         as_of = NULL, point_output_type = \"mean\") } # }"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_hub.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to model output data. — connect_hub","title":"Connect to model output data. — connect_hub","text":"Connect data model output directory Modeling Hub directly. Data can stored local directory cloud AWS GCS.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_hub.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect to model output data. — connect_hub","text":"","code":"connect_hub(   hub_path,   file_format = c(\"csv\", \"parquet\", \"arrow\"),   output_type_id_datatype = c(\"from_config\", \"auto\", \"character\", \"double\", \"integer\",     \"logical\", \"Date\"),   partitions = list(model_id = arrow::utf8()),   skip_checks = FALSE,   na = c(\"NA\", \"\"),   ignore_files = NULL )  connect_model_output(   model_output_dir,   file_format = c(\"csv\", \"parquet\", \"arrow\"),   partition_names = \"model_id\",   schema = NULL,   skip_checks = FALSE,   na = c(\"NA\", \"\"),   ignore_files = NULL )"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_hub.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Connect to model output data. — connect_hub","text":"hub_path Either character string path local Modeling Hub directory object class <SubTreeFileSystem> created using functions s3_bucket() gs_bucket() providing string S3 GCS bucket name path Modeling Hub directory stored cloud. details consult Using cloud storage (S3, GCS) arrow package. hub must fully configured valid admin.json tasks.json files within hub-config directory. file_format file format model output files stored . connection fully configured hub, accessed hub_path, file_format inferred hub's file_format configuration admin.json ignored default. supplied, override hub configuration setting. Multiple formats can supplied connect_hub single file format can supplied connect_model_output. output_type_id_datatype character string. One \"from_config\", \"auto\", \"character\", \"double\", \"integer\", \"logical\", \"Date\". Defaults \"from_config\" uses setting output_type_id_datatype property tasks.json config file available. property set config, argument falls back \"auto\" determines  output_type_id data type automatically tasks.json config file simplest data type required represent output type ID values across output types hub. point estimate output types (output_type_ids NA,) collected hub, output_type_id column assigned character data type auto-determined. data type values can used override automatic determination. Note attempting coerce output_type_id data type valid data (e.g. trying coerce\"character\" values \"double\") likely result error potentially unexpected behaviour use care. partitions named list specifying arrow data types partitioning column. skip_checks Logical. FALSE (default), check file_format parameter hub's model output files. Also excludes invalid model output files opening hub datasets. Setting TRUE improve performance, noticeable large cloud hubs, result error model output directory includes invalid files. invalid (non-model output date files) contained model output directory, use ignore_files argument ignore . na character vector strings interpret missing values. applies CSV files. default c(\"NA\", \"\"). Useful actual character string \"NA\" values used data. case, use empty cells indicate missing values files set na = \"\". ignore_files character vector file names (paths) file prefixes ignore discovering model output files include dataset connections. Parent directory names included. Common non-data files \"README\" \".DS_Store\" ignored automatically, additional files can excluded specifying . model_output_dir Either character string path local directory containing model output data object class <SubTreeFileSystem> created using functions s3_bucket() gs_bucket() providing string S3 GCS bucket name path directory containing model output data stored cloud. details consult Using cloud storage (S3, GCS) arrow package. partition_names character vector defines field names recursive directory names correspond . Defaults single model_id field reflects standard expected structure model-output directory. schema arrow::Schema object Dataset. NULL (default), schema inferred data sources.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_hub.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect to model output data. — connect_hub","text":"connect_hub returns S3 object class <hub_connection>. connect_model_output returns S3 object class <mod_out_connection>. objects connected data model-output directory via Apache arrow FileSystemDataset connection. connection can used extract data using dplyr custom queries. <hub_connection> class also contains modeling hub metadata.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_hub.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Connect to model output data. — connect_hub","text":"default, common non-data files may present model output directories (e.g. \"README\", \".DS_Store\") excluded automatically prevent errors connecting via Arrow. Additional files can excluded using ignore_files parameter.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_hub.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Connect to model output data. — connect_hub","text":"connect_hub(): connect fully configured Modeling Hub directory. connect_model_output(): connect directly model-output directory. function can used access data directly appropriately set model output directory part fully configured hub.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_hub.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Connect to model output data. — connect_hub","text":"","code":"# Connect to a local simple forecasting Hub. hub_path <- system.file(\"testhubs/simple\", package = \"hubUtils\") hub_con <- connect_hub(hub_path) hub_con #>  #> ── <hub_connection/UnionDataset> ── #>  #> • hub_name: \"Simple Forecast Hub\" #> • hub_path: /home/runner/work/_temp/Library/hubUtils/testhubs/simple #> • file_format: \"csv(3/3)\" and \"parquet(1/1)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #> • config_admin: hub-config/admin.json #> • config_tasks: hub-config/tasks.json #>  #> ── Connection schema  #> hub_connection #> 9 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> output_type: string #> output_type_id: double #> value: int32 #> model_id: string #> age_group: string hub_con <- connect_hub(hub_path, output_type_id_datatype = \"character\") hub_con #>  #> ── <hub_connection/UnionDataset> ── #>  #> • hub_name: \"Simple Forecast Hub\" #> • hub_path: /home/runner/work/_temp/Library/hubUtils/testhubs/simple #> • file_format: \"csv(3/3)\" and \"parquet(1/1)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #> • config_admin: hub-config/admin.json #> • config_tasks: hub-config/tasks.json #>  #> ── Connection schema  #> hub_connection #> 9 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> output_type: string #> output_type_id: string #> value: int32 #> model_id: string #> age_group: string # Connect directly to a local `model-output` directory mod_out_path <- system.file(\"testhubs/simple/model-output\", package = \"hubUtils\") mod_out_con <- connect_model_output(mod_out_path) mod_out_con #>  #> ── <mod_out_connection/FileSystemDataset> ── #>  #> • file_format: \"csv(3/3)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #>  #> ── Connection schema  #> mod_out_connection with 3 csv files #> 8 columns #> origin_date: date32[day] #> target: string #> horizon: int64 #> location: string #> output_type: string #> output_type_id: double #> value: int64 #> model_id: string # Query hub_connection for data library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union hub_con %>%   filter(     origin_date == \"2022-10-08\",     horizon == 2   ) %>%   collect_hub() #> # A tibble: 69 × 9 #>    model_id     origin_date target        horizon location age_group output_type #>  * <chr>        <date>      <chr>           <int> <chr>    <chr>     <chr>       #>  1 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #>  2 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #>  3 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #>  4 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #>  5 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #>  6 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #>  7 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #>  8 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #>  9 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #> 10 hub-baseline 2022-10-08  wk inc flu h…       2 US       NA        quantile    #> # ℹ 59 more rows #> # ℹ 2 more variables: output_type_id <chr>, value <int> mod_out_con %>%   filter(     origin_date == \"2022-10-08\",     horizon == 2   ) %>%   collect_hub() #> # A tibble: 69 × 8 #>    model_id origin_date target horizon location output_type output_type_id value #>  * <chr>    <date>      <chr>    <int> <chr>    <chr>                <dbl> <int> #>  1 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.01    135 #>  2 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.025   137 #>  3 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.05    139 #>  4 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.1     140 #>  5 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.15    141 #>  6 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.2     141 #>  7 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.25    142 #>  8 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.3     143 #>  9 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.35    144 #> 10 hub-bas… 2022-10-08  wk in…       2 US       quantile             0.4     145 #> # ℹ 59 more rows # Ignore a file connect_hub(hub_path, ignore_files = c(\"README\", \"2022-10-08-team1-goodmodel.csv\")) #>  #> ── <hub_connection/UnionDataset> ── #>  #> • hub_name: \"Simple Forecast Hub\" #> • hub_path: /home/runner/work/_temp/Library/hubUtils/testhubs/simple #> • file_format: \"csv(2/3)\" and \"parquet(1/1)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #> • config_admin: hub-config/admin.json #> • config_tasks: hub-config/tasks.json #>  #> ── Connection schema  #> hub_connection #> 9 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> output_type: string #> output_type_id: double #> value: int32 #> model_id: string #> age_group: string # Connect to a simple forecasting Hub stored in an AWS S3 bucket. if (FALSE) { # \\dontrun{ hub_path <- s3_bucket(\"hubverse/hubutils/testhubs/simple/\") hub_con <- connect_hub(hub_path) hub_con } # }"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_oracle_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Open connection to oracle-output target data — connect_target_oracle_output","title":"Open connection to oracle-output target data — connect_target_oracle_output","text":"Open oracle-output target data file(s) hub arrow dataset.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_oracle_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open connection to oracle-output target data — connect_target_oracle_output","text":"","code":"connect_target_oracle_output(   hub_path = \".\",   na = c(\"NA\", \"\"),   ignore_files = NULL,   output_type_id_datatype = c(\"from_config\", \"auto\", \"character\", \"double\", \"integer\",     \"logical\", \"Date\") )"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_oracle_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Open connection to oracle-output target data — connect_target_oracle_output","text":"hub_path Either character string path local Modeling Hub directory object class <SubTreeFileSystem> created using functions s3_bucket() gs_bucket() providing string S3 GCS bucket name path Modeling Hub directory stored cloud. details consult Using cloud storage (S3, GCS) arrow package. hub must fully configured valid admin.json tasks.json files within hub-config directory. na character vector strings interpret missing values. applies CSV files. default c(\"NA\", \"\"). Useful actual character string \"NA\" values used data. case, use empty cells indicate missing values files set na = \"\". ignore_files character vector file names (paths) file prefixes ignore discovering model output files include dataset connections. Parent directory names included. Common non-data files \"README\" \".DS_Store\" ignored automatically, additional files can excluded specifying . output_type_id_datatype character string. One \"from_config\", \"auto\", \"character\", \"double\", \"integer\", \"logical\", \"Date\". Defaults \"from_config\" uses setting output_type_id_datatype property tasks.json config file available. property set config, argument falls back \"auto\" determines  output_type_id data type automatically tasks.json config file simplest data type required represent output type ID values across output types hub. point estimate output types (output_type_ids NA,) collected hub, output_type_id column assigned character data type auto-determined. data type values can used override automatic determination. Note attempting coerce output_type_id data type valid data (e.g. trying coerce\"character\" values \"double\") likely result error potentially unexpected behaviour use care.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_oracle_output.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Open connection to oracle-output target data — connect_target_oracle_output","text":"arrow dataset object subclass <target_oracle_output>.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_oracle_output.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Open connection to oracle-output target data — connect_target_oracle_output","text":"target data split across multiple files oracle-output directory, files must share file format, either csv parquet. types files currently allowed oracle-output directory.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_oracle_output.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Open connection to oracle-output target data — connect_target_oracle_output","text":"","code":"# Clone example hub tmp_hub_path <- withr::local_tempdir() example_hub <- \"https://github.com/hubverse-org/example-complex-forecast-hub.git\" gert::git_clone(url = example_hub, path = tmp_hub_path) # Connect to oracle-output data oo_con <- connect_target_oracle_output(tmp_hub_path) oo_con #> target_oracle_output with 1 csv file #> 6 columns #> location: string #> target_end_date: date32[day] #> target: string #> output_type: string #> output_type_id: string #> oracle_value: double # Collect all oracle-output data oo_con |> dplyr::collect() #> # A tibble: 200,340 × 6 #>    location target_end_date target       output_type output_type_id oracle_value #>    <chr>    <date>          <chr>        <chr>       <chr>                 <dbl> #>  1 US       2022-10-22      wk inc flu … quantile    NA                     2380 #>  2 01       2022-10-22      wk inc flu … quantile    NA                      141 #>  3 02       2022-10-22      wk inc flu … quantile    NA                        3 #>  4 04       2022-10-22      wk inc flu … quantile    NA                       22 #>  5 05       2022-10-22      wk inc flu … quantile    NA                       50 #>  6 06       2022-10-22      wk inc flu … quantile    NA                      124 #>  7 08       2022-10-22      wk inc flu … quantile    NA                       15 #>  8 09       2022-10-22      wk inc flu … quantile    NA                        9 #>  9 10       2022-10-22      wk inc flu … quantile    NA                        1 #> 10 11       2022-10-22      wk inc flu … quantile    NA                        8 #> # ℹ 200,330 more rows # Filter for a specific date before collecting oo_con |>   dplyr::filter(target_end_date == \"2022-11-12\") |>   dplyr::collect() #> # A tibble: 5,724 × 6 #>    location target_end_date target       output_type output_type_id oracle_value #>    <chr>    <date>          <chr>        <chr>       <chr>                 <dbl> #>  1 US       2022-11-12      wk inc flu … quantile    NA                     8848 #>  2 01       2022-11-12      wk inc flu … quantile    NA                      303 #>  3 02       2022-11-12      wk inc flu … quantile    NA                       20 #>  4 04       2022-11-12      wk inc flu … quantile    NA                      153 #>  5 05       2022-11-12      wk inc flu … quantile    NA                      212 #>  6 06       2022-11-12      wk inc flu … quantile    NA                      928 #>  7 08       2022-11-12      wk inc flu … quantile    NA                       61 #>  8 09       2022-11-12      wk inc flu … quantile    NA                       58 #>  9 10       2022-11-12      wk inc flu … quantile    NA                       15 #> 10 11       2022-11-12      wk inc flu … quantile    NA                       44 #> # ℹ 5,714 more rows # Filter for a specific location before collecting oo_con |>   dplyr::filter(location == \"US\") |>   dplyr::collect() #> # A tibble: 3,780 × 6 #>    location target_end_date target       output_type output_type_id oracle_value #>    <chr>    <date>          <chr>        <chr>       <chr>                 <dbl> #>  1 US       2022-10-22      wk inc flu … quantile    NA                     2380 #>  2 US       2022-10-29      wk inc flu … quantile    NA                     4353 #>  3 US       2022-11-05      wk inc flu … quantile    NA                     6571 #>  4 US       2022-11-12      wk inc flu … quantile    NA                     8848 #>  5 US       2022-11-19      wk inc flu … quantile    NA                    11427 #>  6 US       2022-11-26      wk inc flu … quantile    NA                    19846 #>  7 US       2022-12-03      wk inc flu … quantile    NA                    26333 #>  8 US       2022-12-10      wk inc flu … quantile    NA                    23851 #>  9 US       2022-12-17      wk inc flu … quantile    NA                    21435 #> 10 US       2022-12-24      wk inc flu … quantile    NA                    19286 #> # ℹ 3,770 more rows # Get distinct target_end_date values oo_con |>   dplyr::distinct(target_end_date) |>   dplyr::pull(as_vector = TRUE) #>  [1] \"2022-10-22\" \"2022-10-29\" \"2022-11-05\" \"2022-11-12\" \"2022-11-19\" #>  [6] \"2022-11-26\" \"2022-12-03\" \"2022-12-10\" \"2022-12-17\" \"2022-12-24\" #> [11] \"2022-12-31\" \"2023-01-07\" \"2023-01-14\" \"2023-01-21\" \"2023-01-28\" #> [16] \"2023-02-04\" \"2023-02-11\" \"2023-02-18\" \"2023-02-25\" \"2023-03-04\" #> [21] \"2023-03-11\" \"2023-03-18\" \"2023-03-25\" \"2023-04-01\" \"2023-04-08\" #> [26] \"2023-04-15\" \"2023-04-22\" \"2023-04-29\" \"2023-05-06\" \"2023-05-13\" #> [31] \"2023-05-20\" \"2023-05-27\" \"2023-06-03\" \"2023-06-10\" \"2023-06-17\" # Access Target oracle-output data from a cloud hub s3_hub_path <- s3_bucket(\"example-complex-forecast-hub\") s3_con <- connect_target_oracle_output(s3_hub_path) s3_con #> target_oracle_output with 1 csv file #> 6 columns #> location: string #> target_end_date: date32[day] #> target: string #> output_type: string #> output_type_id: string #> oracle_value: double s3_con |> dplyr::collect() #> # A tibble: 200,340 × 6 #>    location target_end_date target       output_type output_type_id oracle_value #>    <chr>    <date>          <chr>        <chr>       <chr>                 <dbl> #>  1 US       2022-10-22      wk inc flu … quantile    NA                     2380 #>  2 01       2022-10-22      wk inc flu … quantile    NA                      141 #>  3 02       2022-10-22      wk inc flu … quantile    NA                        3 #>  4 04       2022-10-22      wk inc flu … quantile    NA                       22 #>  5 05       2022-10-22      wk inc flu … quantile    NA                       50 #>  6 06       2022-10-22      wk inc flu … quantile    NA                      124 #>  7 08       2022-10-22      wk inc flu … quantile    NA                       15 #>  8 09       2022-10-22      wk inc flu … quantile    NA                        9 #>  9 10       2022-10-22      wk inc flu … quantile    NA                        1 #> 10 11       2022-10-22      wk inc flu … quantile    NA                        8 #> # ℹ 200,330 more rows"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_timeseries.html","id":null,"dir":"Reference","previous_headings":"","what":"Open connection to time-series target data — connect_target_timeseries","title":"Open connection to time-series target data — connect_target_timeseries","text":"Open time-series target data file(s) hub arrow dataset.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_timeseries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open connection to time-series target data — connect_target_timeseries","text":"","code":"connect_target_timeseries(   hub_path = \".\",   date_col = NULL,   na = c(\"NA\", \"\"),   ignore_files = NULL )"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_timeseries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Open connection to time-series target data — connect_target_timeseries","text":"hub_path Either character string path local Modeling Hub directory object class <SubTreeFileSystem> created using functions s3_bucket() gs_bucket() providing string S3 GCS bucket name path Modeling Hub directory stored cloud. details consult Using cloud storage (S3, GCS) arrow package. hub must fully configured valid admin.json tasks.json files within hub-config directory. date_col Optional column name interpreted date. Default NULL. Useful required date column partitioning column target data name date typed task ID variable config. na character vector strings interpret missing values. applies CSV files. default c(\"NA\", \"\"). Useful actual character string \"NA\" values used data. case, use empty cells indicate missing values files set na = \"\". ignore_files character vector file names (paths) file prefixes ignore discovering model output files include dataset connections. Parent directory names included. Common non-data files \"README\" \".DS_Store\" ignored automatically, additional files can excluded specifying .","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_timeseries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Open connection to time-series target data — connect_target_timeseries","text":"arrow dataset object subclass <target_timeseries>.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_timeseries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Open connection to time-series target data — connect_target_timeseries","text":"target data split across multiple files time-series directory, files must share file format, either csv parquet. types files currently allowed time-series directory.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/connect_target_timeseries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Open connection to time-series target data — connect_target_timeseries","text":"","code":"# Clone example hub tmp_hub_path <- withr::local_tempdir() example_hub <- \"https://github.com/hubverse-org/example-complex-forecast-hub.git\" gert::git_clone(url = example_hub, path = tmp_hub_path) # Connect to time-series data ts_con <- connect_target_timeseries(tmp_hub_path) ts_con #> target_timeseries with 1 csv file #> 4 columns #> date: date32[day] #> target: string #> location: string #> observation: double # Collect all time-series data ts_con |> dplyr::collect() #> # A tibble: 20,510 × 4 #>    date       target          location observation #>    <date>     <chr>           <chr>          <dbl> #>  1 2020-01-11 wk inc flu hosp 01                 0 #>  2 2020-01-11 wk inc flu hosp 15                 0 #>  3 2020-01-11 wk inc flu hosp 18                 0 #>  4 2020-01-11 wk inc flu hosp 27                 0 #>  5 2020-01-11 wk inc flu hosp 30                 0 #>  6 2020-01-11 wk inc flu hosp 37                 0 #>  7 2020-01-11 wk inc flu hosp 48                 0 #>  8 2020-01-11 wk inc flu hosp US                 1 #>  9 2020-01-18 wk inc flu hosp 01                 0 #> 10 2020-01-18 wk inc flu hosp 15                 0 #> # ℹ 20,500 more rows # Filter for a specific date before collecting ts_con |>   dplyr::filter(date == \"2020-01-11\") |>   dplyr::collect() #> # A tibble: 16 × 4 #>    date       target           location observation #>    <date>     <chr>            <chr>          <dbl> #>  1 2020-01-11 wk inc flu hosp  01          0        #>  2 2020-01-11 wk inc flu hosp  15          0        #>  3 2020-01-11 wk inc flu hosp  18          0        #>  4 2020-01-11 wk inc flu hosp  27          0        #>  5 2020-01-11 wk inc flu hosp  30          0        #>  6 2020-01-11 wk inc flu hosp  37          0        #>  7 2020-01-11 wk inc flu hosp  48          0        #>  8 2020-01-11 wk inc flu hosp  US          1        #>  9 2020-01-11 wk flu hosp rate 01          0        #> 10 2020-01-11 wk flu hosp rate 15          0        #> 11 2020-01-11 wk flu hosp rate 18          0        #> 12 2020-01-11 wk flu hosp rate 27          0        #> 13 2020-01-11 wk flu hosp rate 30          0        #> 14 2020-01-11 wk flu hosp rate 37          0        #> 15 2020-01-11 wk flu hosp rate 48          0        #> 16 2020-01-11 wk flu hosp rate US          0.000301 # Filter for a specific location before collecting ts_con |>   dplyr::filter(location == \"US\") |>   dplyr::collect() #> # A tibble: 402 × 4 #>    date       target          location observation #>    <date>     <chr>           <chr>          <dbl> #>  1 2020-01-11 wk inc flu hosp US                 1 #>  2 2020-01-18 wk inc flu hosp US                 0 #>  3 2020-01-25 wk inc flu hosp US                 0 #>  4 2020-02-01 wk inc flu hosp US                 0 #>  5 2020-02-08 wk inc flu hosp US                 0 #>  6 2020-02-15 wk inc flu hosp US                 0 #>  7 2020-02-22 wk inc flu hosp US                 0 #>  8 2020-02-29 wk inc flu hosp US                 0 #>  9 2020-03-07 wk inc flu hosp US                 0 #> 10 2020-03-14 wk inc flu hosp US                 0 #> # ℹ 392 more rows # Access Target time-series data from a cloud hub s3_hub_path <- s3_bucket(\"example-complex-forecast-hub\") s3_con <- connect_target_timeseries(s3_hub_path) s3_con #> target_timeseries with 1 csv file #> 4 columns #> date: date32[day] #> target: string #> location: string #> observation: double s3_con |> dplyr::collect() #> # A tibble: 20,510 × 4 #>    date       target          location observation #>    <date>     <chr>           <chr>          <dbl> #>  1 2020-01-11 wk inc flu hosp 01                 0 #>  2 2020-01-11 wk inc flu hosp 15                 0 #>  3 2020-01-11 wk inc flu hosp 18                 0 #>  4 2020-01-11 wk inc flu hosp 27                 0 #>  5 2020-01-11 wk inc flu hosp 30                 0 #>  6 2020-01-11 wk inc flu hosp 37                 0 #>  7 2020-01-11 wk inc flu hosp 48                 0 #>  8 2020-01-11 wk inc flu hosp US                 1 #>  9 2020-01-18 wk inc flu hosp 01                 0 #> 10 2020-01-18 wk inc flu hosp 15                 0 #> # ℹ 20,500 more rows"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_hub_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Hub arrow schema — create_hub_schema","title":"Create a Hub arrow schema — create_hub_schema","text":"Create arrow schema tasks.json config file. use opening arrow dataset.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_hub_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Hub arrow schema — create_hub_schema","text":"","code":"create_hub_schema(   config_tasks,   partitions = list(model_id = arrow::utf8()),   output_type_id_datatype = c(\"from_config\", \"auto\", \"character\", \"double\", \"integer\",     \"logical\", \"Date\"),   r_schema = FALSE )"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_hub_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Hub arrow schema — create_hub_schema","text":"config_tasks list version content's hub's tasks.json config file created using function hubUtils::read_config(). partitions named list specifying arrow data types partitioning column. output_type_id_datatype character string. One \"from_config\", \"auto\", \"character\", \"double\", \"integer\", \"logical\", \"Date\". Defaults \"from_config\" uses setting output_type_id_datatype property tasks.json config file available. property set config, argument falls back \"auto\" determines  output_type_id data type automatically tasks.json config file simplest data type required represent output type ID values across output types hub. point estimate output types (output_type_ids NA,) collected hub, output_type_id column assigned character data type auto-determined. data type values can used override automatic determination. Note attempting coerce output_type_id data type valid data (e.g. trying coerce\"character\" values \"double\") likely result error potentially unexpected behaviour use care. r_schema Logical. FALSE (default), return arrow::schema() object. TRUE, return character vector R data types.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_hub_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Hub arrow schema — create_hub_schema","text":"arrow schema object can used define column datatypes opening model output data. r_schema = TRUE, character vector R data types.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_hub_schema.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Hub arrow schema — create_hub_schema","text":"","code":"hub_path <- system.file(\"testhubs/simple\", package = \"hubUtils\") config_tasks <- hubUtils::read_config(hub_path, \"tasks\") schema <- create_hub_schema(config_tasks)"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_model_out_submit_tmpl.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a model output submission file template — create_model_out_submit_tmpl","title":"Create a model output submission file template — create_model_out_submit_tmpl","text":"function moved hubValidations package renamed submission_tmpl().","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_model_out_submit_tmpl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a model output submission file template — create_model_out_submit_tmpl","text":"","code":"create_model_out_submit_tmpl(   hub_con,   config_tasks,   round_id,   required_vals_only = FALSE,   complete_cases_only = TRUE )"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_model_out_submit_tmpl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a model output submission file template — create_model_out_submit_tmpl","text":"hub_con ⁠<hub_connection>⁠ class object. config_tasks list version content's hub's tasks.json config file, accessed \"config_tasks\" attribute <hub_connection> object function hubUtils::read_config(). round_id Character string. Round identifier. round set round_id_from_variable: true, IDs values task ID defined round's round_id property config_tasks. Otherwise match round's round_id value config. Ignored hub contains single round. required_vals_only Logical. Whether return combinations Task ID related output type ID required values. complete_cases_only Logical. TRUE (default) required_vals_only = TRUE, rows complete cases combinations required values returned. FALSE, rows incomplete cases combinations required values included output.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_model_out_submit_tmpl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a model output submission file template — create_model_out_submit_tmpl","text":"tibble template containing expanded grid valid task ID output type ID value combinations given submission round output type. required_vals_only = TRUE, values limited combination required values .","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_model_out_submit_tmpl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a model output submission file template — create_model_out_submit_tmpl","text":"task IDs output_type_ids values optional, default, columns included columns NAs required_vals_only = TRUE. columns exist, function returns tibble zero rows, complete cases required value combinations exists. (Note determination complete cases excludes valid NA output_type_id values \"mean\" \"median\" output types). return template incomplete required cases, includes NA columns, use complete_cases_only = FALSE. sample output types included output, output_type_id column contains example sample indexes useful identifying compound task ID structure multivariate sampling distributions particular, .e. combinations task ID values represent individual samples. round set round_id_from_variable: true, value task ID round IDs derived (.e. task ID specified round_id property config_tasks) set value round_id argument returned output.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_oracle_output_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Create oracle-output target data file schema — create_oracle_output_schema","title":"Create oracle-output target data file schema — create_oracle_output_schema","text":"Create oracle-output target data file schema","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_oracle_output_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create oracle-output target data file schema — create_oracle_output_schema","text":"","code":"create_oracle_output_schema(   hub_path,   na = c(\"NA\", \"\"),   ignore_files = NULL,   r_schema = FALSE,   output_type_id_datatype = c(\"from_config\", \"auto\", \"character\", \"double\", \"integer\",     \"logical\", \"Date\") )"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_oracle_output_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create oracle-output target data file schema — create_oracle_output_schema","text":"hub_path Either character string path local Modeling Hub directory object class <SubTreeFileSystem> created using functions s3_bucket() gs_bucket() providing string S3 GCS bucket name path Modeling Hub directory stored cloud. details consult Using cloud storage (S3, GCS) arrow package. hub must fully configured valid admin.json tasks.json files within hub-config directory. na character vector strings interpret missing values. applies CSV files. default c(\"NA\", \"\"). Useful actual character string \"NA\" values used data. case, use empty cells indicate missing values files set na = \"\". ignore_files character vector file names (paths) file prefixes ignore discovering model output files include dataset connections. Parent directory names included. Common non-data files \"README\" \".DS_Store\" ignored automatically, additional files can excluded specifying . r_schema Logical. FALSE (default), return arrow::schema() object. TRUE, return character vector R data types. output_type_id_datatype character string. One \"from_config\", \"auto\", \"character\", \"double\", \"integer\", \"logical\", \"Date\". Defaults \"from_config\" uses setting output_type_id_datatype property tasks.json config file available. property set config, argument falls back \"auto\" determines  output_type_id data type automatically tasks.json config file simplest data type required represent output type ID values across output types hub. point estimate output types (output_type_ids NA,) collected hub, output_type_id column assigned character data type auto-determined. data type values can used override automatic determination. Note attempting coerce output_type_id data type valid data (e.g. trying coerce\"character\" values \"double\") likely result error potentially unexpected behaviour use care.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_oracle_output_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create oracle-output target data file schema — create_oracle_output_schema","text":"arrow <schema> class object","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_oracle_output_schema.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create oracle-output target data file schema — create_oracle_output_schema","text":"","code":"#' # Clone example hub tmp_hub_path <- withr::local_tempdir() example_hub <- \"https://github.com/hubverse-org/example-complex-forecast-hub.git\" gert::git_clone(url = example_hub, path = tmp_hub_path) # Create target oracle-output schema create_oracle_output_schema(tmp_hub_path) #> Schema #> location: string #> target_end_date: date32[day] #> target: string #> output_type: string #> output_type_id: string #> oracle_value: double #  target oracle-output schema from a cloud hub s3_hub_path <- s3_bucket(\"example-complex-forecast-hub\") create_oracle_output_schema(s3_hub_path) #> Schema #> location: string #> target_end_date: date32[day] #> target: string #> output_type: string #> output_type_id: string #> oracle_value: double"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_timeseries_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Create time-series target data file schema — create_timeseries_schema","title":"Create time-series target data file schema — create_timeseries_schema","text":"Create time-series target data file schema","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_timeseries_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create time-series target data file schema — create_timeseries_schema","text":"","code":"create_timeseries_schema(   hub_path,   date_col = NULL,   na = c(\"NA\", \"\"),   ignore_files = NULL,   r_schema = FALSE )"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_timeseries_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create time-series target data file schema — create_timeseries_schema","text":"hub_path Either character string path local Modeling Hub directory object class <SubTreeFileSystem> created using functions s3_bucket() gs_bucket() providing string S3 GCS bucket name path Modeling Hub directory stored cloud. details consult Using cloud storage (S3, GCS) arrow package. hub must fully configured valid admin.json tasks.json files within hub-config directory. date_col Optional column name interpreted date. Default NULL. Useful required date column partitioning column target data name date typed task ID variable config. na character vector strings interpret missing values. applies CSV files. default c(\"NA\", \"\"). Useful actual character string \"NA\" values used data. case, use empty cells indicate missing values files set na = \"\". ignore_files character vector file names (paths) file prefixes ignore discovering model output files include dataset connections. Parent directory names included. Common non-data files \"README\" \".DS_Store\" ignored automatically, additional files can excluded specifying . r_schema Logical. FALSE (default), return arrow::schema() object. TRUE, return character vector R data types.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_timeseries_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create time-series target data file schema — create_timeseries_schema","text":"arrow <schema> class object","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/create_timeseries_schema.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create time-series target data file schema — create_timeseries_schema","text":"","code":"#' # Clone example hub tmp_hub_path <- withr::local_tempdir() example_hub <- \"https://github.com/hubverse-org/example-complex-forecast-hub.git\" gert::git_clone(url = example_hub, path = tmp_hub_path) # Create target time-series schema create_timeseries_schema(tmp_hub_path) #> Schema #> date: date32[day] #> target: string #> location: string #> observation: double #  target time-series schema from a cloud hub s3_hub_path <- s3_bucket(\"example-complex-forecast-hub\") create_timeseries_schema(s3_hub_path) #> Schema #> date: date32[day] #> target: string #> location: string #> observation: double"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/expand_model_out_val_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Create expanded grid of valid task ID and output type value combinations — expand_model_out_val_grid","title":"Create expanded grid of valid task ID and output type value combinations — expand_model_out_val_grid","text":"function moved hubValidations package renamed expand_model_out_grid().","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/expand_model_out_val_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create expanded grid of valid task ID and output type value combinations — expand_model_out_val_grid","text":"","code":"expand_model_out_val_grid(   config_tasks,   round_id,   required_vals_only = FALSE,   all_character = FALSE,   as_arrow_table = FALSE,   bind_model_tasks = TRUE,   include_sample_ids = FALSE )"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/expand_model_out_val_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create expanded grid of valid task ID and output type value combinations — expand_model_out_val_grid","text":"config_tasks list version content's hub's tasks.json config file, accessed \"config_tasks\" attribute <hub_connection> object function hubUtils::read_config(). round_id Character string. Round identifier. round set round_id_from_variable: true, IDs values task ID defined round's round_id property config_tasks. Otherwise match round's round_id value config. Ignored hub contains single round. required_vals_only Logical. Whether return combinations Task ID related output type ID required values. all_character Logical. Whether return character column. as_arrow_table Logical. Whether return arrow table. Defaults FALSE. bind_model_tasks Logical. Whether bind expanded grids values multiple modeling tasks single tibble/arrow table return list. include_sample_ids Logical. Whether include sample identifiers output_type_id column.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/expand_model_out_val_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create expanded grid of valid task ID and output type value combinations — expand_model_out_val_grid","text":"bind_model_tasks = TRUE (default) tibble arrow table containing possible task ID related output type ID value combinations. bind_model_tasks = FALSE, list containing tibble arrow table round modeling task. Columns coerced data types according hub schema, unless all_character = TRUE. all_character = TRUE, columns returned character can faster large expanded grids expected. required_vals_only = TRUE, values limited combinations required values .","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/expand_model_out_val_grid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create expanded grid of valid task ID and output type value combinations — expand_model_out_val_grid","text":"round set round_id_from_variable: true, value task ID round IDs derived (.e. task ID specified round_id property config_tasks) set value round_id argument returned output. sample output types included output include_sample_ids = TRUE, output_type_id column contains example sample indexes useful identifying compound task ID structure multivariate sampling distributions particular, .e. combinations task ID values represent individual samples.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_s3_bucket_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the bucket name for the cloud storage location. — get_s3_bucket_name","title":"Get the bucket name for the cloud storage location. — get_s3_bucket_name","text":"Get bucket name cloud storage location.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_s3_bucket_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the bucket name for the cloud storage location. — get_s3_bucket_name","text":"","code":"get_s3_bucket_name(hub_path = \".\")"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_s3_bucket_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the bucket name for the cloud storage location. — get_s3_bucket_name","text":"hub_path Path hub directory.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_s3_bucket_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the bucket name for the cloud storage location. — get_s3_bucket_name","text":"bucket name cloud storage location.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_s3_bucket_name.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the bucket name for the cloud storage location. — get_s3_bucket_name","text":"","code":"hub_path <- withr::local_tempdir() example_hub <- \"https://github.com/hubverse-org/example-complex-forecast-hub.git\" gert::git_clone(url = example_hub, path = hub_path) get_s3_bucket_name(hub_path) #> [1] \"example-complex-forecast-hub\" # Get config info from GitHub get_s3_bucket_name(   \"https://github.com/hubverse-org/example-complex-forecast-hub\" ) #> [1] \"example-complex-forecast-hub\""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_target_file_ext.html","id":null,"dir":"Reference","previous_headings":"","what":"Get target data file unique file extensions. — get_target_file_ext","title":"Get target data file unique file extensions. — get_target_file_ext","text":"Get unique file extension(s) target data file(s) target_path. target_path directory, function return unique file extensions files directory. target_path file, function return file extension file.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_target_file_ext.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get target data file unique file extensions. — get_target_file_ext","text":"","code":"get_target_file_ext(hub_path = NULL, target_path)"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_target_file_ext.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get target data file unique file extensions. — get_target_file_ext","text":"hub_path NULL, must SubTreeFileSystem class object root cloud hosted hub. Required trigger SubTreeFileSystem method. target_path character string. path target data file directory. Usually output get_target_path().","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_target_file_ext.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get target data file unique file extensions. — get_target_file_ext","text":"","code":"hub_path <- withr::local_tempdir() example_hub <- \"https://github.com/hubverse-org/example-complex-forecast-hub.git\" gert::git_clone(url = example_hub, path = hub_path) target_path <- get_target_path(hub_path, \"time-series\") get_target_file_ext(hub_path, target_path) #> [1] \"csv\""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_target_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the path(s) to the target data file(s) in the hub directory. — get_target_path","title":"Get the path(s) to the target data file(s) in the hub directory. — get_target_path","text":"Get path(s) target data file(s) hub directory.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_target_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the path(s) to the target data file(s) in the hub directory. — get_target_path","text":"","code":"get_target_path(hub_path, target_type = c(\"time-series\", \"oracle-output\"))"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_target_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the path(s) to the target data file(s) in the hub directory. — get_target_path","text":"hub_path Either character string path local Modeling Hub directory object class <SubTreeFileSystem> created using functions s3_bucket() gs_bucket() providing string S3 GCS bucket name path Modeling Hub directory stored cloud. details consult Using cloud storage (S3, GCS) arrow package. hub must fully configured valid admin.json tasks.json files within hub-config directory. target_type Type target data retrieve matching files. One \"time-series\" \"oracle-output\". Defaults \"time-series\".","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_target_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the path(s) to the target data file(s) in the hub directory. — get_target_path","text":"character vector path(s) target data file(s) (target-data directory) make target_type requested.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/get_target_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the path(s) to the target data file(s) in the hub directory. — get_target_path","text":"","code":"hub_path <- withr::local_tempdir() example_hub <- \"https://github.com/hubverse-org/example-complex-forecast-hub.git\" gert::git_clone(url = example_hub, path = hub_path) get_target_path(hub_path) #> /tmp/Rtmpq5s8En/file1dea18128fce/target-data/time-series.csv get_target_path(hub_path, \"time-series\") #> /tmp/Rtmpq5s8En/file1dea18128fce/target-data/time-series.csv get_target_path(hub_path, \"oracle-output\") #> /tmp/Rtmpq5s8En/file1dea18128fce/target-data/oracle-output.csv # Access cloud data s3_bucket_name <- get_s3_bucket_name(hub_path) s3_hub_path <- s3_bucket(s3_bucket_name) get_target_path(s3_hub_path) #> target-data/time-series.csv get_target_path(s3_hub_path, \"oracle-output\") #> target-data/oracle-output.csv"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/gs_bucket.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to a Google Cloud Storage (GCS) bucket — gs_bucket","title":"Connect to a Google Cloud Storage (GCS) bucket — gs_bucket","text":"See arrow::gs_bucket() details.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/gs_bucket.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect to a Google Cloud Storage (GCS) bucket — gs_bucket","text":"SubTreeFileSystem containing GcsFileSystem bucket's relative path. Note function's success guarantee authorized access bucket's contents.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/gs_bucket.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Connect to a Google Cloud Storage (GCS) bucket — gs_bucket","text":"","code":"if (FALSE) { bucket <- gs_bucket(\"voltrondata-labs-datasets\") }"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/hubData-package.html","id":null,"dir":"Reference","previous_headings":"","what":"hubData: Tools for accessing and working with hubverse data — hubData-package","title":"hubData: Tools for accessing and working with hubverse data — hubData-package","text":"set utility functions accessing working forecast target data Infectious Disease Modeling Hubs.","code":""},{"path":[]},{"path":"https://hubverse-org.github.io/hubData/dev/reference/hubData-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"hubData: Tools for accessing and working with hubverse data — hubData-package","text":"Maintainer: Anna Krystalli annakrystalli@googlemail.com (ORCID) contributors: Li Shandross lshandross@umass.edu [contributor] Nicholas G. Reich nick@umass.edu (ORCID) [contributor] Evan L. Ray elray@umass.edu [contributor] Becky Sweger bsweger@gmail.com [contributor] Consortium Infectious Disease Modeling Hubs [copyright holder]","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/load_model_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Compile hub model metadata — load_model_metadata","title":"Compile hub model metadata — load_model_metadata","text":"Loads hub model metadata models specified subset models compiles tibble one row per model.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/load_model_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compile hub model metadata — load_model_metadata","text":"","code":"load_model_metadata(hub_path, model_ids = NULL)"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/load_model_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compile hub model metadata — load_model_metadata","text":"hub_path Either character string path local Modeling Hub directory object class <SubTreeFileSystem> created using functions s3_bucket() gs_bucket() providing string S3 GCS bucket name path Modeling Hub directory stored cloud. details consult Using cloud storage (S3, GCS) arrow package. model_ids vector character strings models load metadata. Defaults NULL, case metadata models loaded.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/load_model_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compile hub model metadata — load_model_metadata","text":"tibble model metadata. One row model, one column top-level field metadata file. metadata files nested structures, tibble may contain list-columns entries lists containing nested metadata values.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/load_model_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compile hub model metadata — load_model_metadata","text":"","code":"# Load in model metadata from local hub hub_path <- system.file(\"testhubs/simple\", package = \"hubUtils\") load_model_metadata(hub_path) #> # A tibble: 2 × 15 #>   model_id        team_abbr model_abbr team_name        model_name model_version #>   <chr>           <chr>     <chr>      <chr>            <chr>      <chr>         #> 1 hub-baseline    hub       baseline   Hub Coordinatio… Baseline   1.0           #> 2 team1-goodmodel team1     goodmodel  Team1            Good Model 1.0           #> # ℹ 9 more variables: model_contributors <list>, website_url <chr>, #> #   repo_url <lgl>, license <chr>, include_viz <lgl>, include_ensemble <lgl>, #> #   include_eval <lgl>, model_details <list>, ensemble_of_hub_models <lgl> load_model_metadata(hub_path, model_ids = c(\"hub-baseline\")) #> # A tibble: 1 × 15 #>   model_id     team_abbr model_abbr team_name           model_name model_version #>   <chr>        <chr>     <chr>      <chr>               <chr>      <chr>         #> 1 hub-baseline hub       baseline   Hub Coordination T… Baseline   1.0           #> # ℹ 9 more variables: model_contributors <list>, website_url <chr>, #> #   repo_url <lgl>, license <chr>, include_viz <lgl>, include_ensemble <lgl>, #> #   include_eval <lgl>, model_details <list>, ensemble_of_hub_models <lgl>"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/print.hub_connection.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a <hub_connection> or <mod_out_connection> S3 class object — print.hub_connection","title":"Print a <hub_connection> or <mod_out_connection> S3 class object — print.hub_connection","text":"Print <hub_connection> <mod_out_connection> S3 class object","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/print.hub_connection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a <hub_connection> or <mod_out_connection> S3 class object — print.hub_connection","text":"","code":"# S3 method for class 'hub_connection' print(x, verbose = FALSE, ...)  # S3 method for class 'mod_out_connection' print(x, verbose = FALSE, ...)"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/print.hub_connection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a <hub_connection> or <mod_out_connection> S3 class object — print.hub_connection","text":"x <hub_connection> <mod_out_connection> S3 class object. verbose Logical. Whether print full structure object. Defaults FALSE. ... arguments passed methods.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/print.hub_connection.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Print a <hub_connection> or <mod_out_connection> S3 class object — print.hub_connection","text":"print(hub_connection): print <hub_connection> object. print(mod_out_connection): print <mod_out_connection> object.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/print.hub_connection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print a <hub_connection> or <mod_out_connection> S3 class object — print.hub_connection","text":"","code":"hub_path <- system.file(\"testhubs/simple\", package = \"hubUtils\") hub_con <- connect_hub(hub_path) hub_con #>  #> ── <hub_connection/UnionDataset> ── #>  #> • hub_name: \"Simple Forecast Hub\" #> • hub_path: /home/runner/work/_temp/Library/hubUtils/testhubs/simple #> • file_format: \"csv(3/3)\" and \"parquet(1/1)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #> • config_admin: hub-config/admin.json #> • config_tasks: hub-config/tasks.json #>  #> ── Connection schema  #> hub_connection #> 9 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> output_type: string #> output_type_id: double #> value: int32 #> model_id: string #> age_group: string print(hub_con) #>  #> ── <hub_connection/UnionDataset> ── #>  #> • hub_name: \"Simple Forecast Hub\" #> • hub_path: /home/runner/work/_temp/Library/hubUtils/testhubs/simple #> • file_format: \"csv(3/3)\" and \"parquet(1/1)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #> • config_admin: hub-config/admin.json #> • config_tasks: hub-config/tasks.json #>  #> ── Connection schema  #> hub_connection #> 9 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> output_type: string #> output_type_id: double #> value: int32 #> model_id: string #> age_group: string print(hub_con, verbose = TRUE) #>  #> ── <hub_connection/UnionDataset> ── #>  #> • hub_name: \"Simple Forecast Hub\" #> • hub_path: /home/runner/work/_temp/Library/hubUtils/testhubs/simple #> • file_format: \"csv(3/3)\" and \"parquet(1/1)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #> • config_admin: hub-config/admin.json #> • config_tasks: hub-config/tasks.json #>  #> ── Connection schema  #> hub_connection #> 9 columns #> origin_date: date32[day] #> target: string #> horizon: int32 #> location: string #> output_type: string #> output_type_id: double #> value: int32 #> model_id: string #> age_group: string #> Classes 'hub_connection', 'UnionDataset', 'Dataset', 'ArrowObject', 'R6' <hub_connection> #>   Inherits from: <UnionDataset> #>   Public: #>     .:xp:.: externalptr #>     .unsafe_delete: function ()  #>     NewScan: function ()  #>     ToString: function ()  #>     WithSchema: function (schema)  #>     children: active binding #>     class_title: function ()  #>     clone: function (deep = FALSE)  #>     initialize: function (xp)  #>     metadata: active binding #>     num_cols: active binding #>     num_rows: active binding #>     pointer: function ()  #>     print: function (...)  #>     schema: active binding #>     set_pointer: function (xp)  #>     type: active binding  #>  - attr(*, \"hub_name\")= chr \"Simple Forecast Hub\" #>  - attr(*, \"file_format\")= int [1:2, 1:2] 3 3 1 1 #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:2] \"n_open\" \"n_in_dir\" #>   .. ..$ : chr [1:2] \"csv\" \"parquet\" #>  - attr(*, \"checks\")= logi TRUE #>  - attr(*, \"file_system\")= chr \"LocalFileSystem\" #>  - attr(*, \"hub_path\")= chr \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple\" #>  - attr(*, \"model_output_dir\")= chr \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #>  - attr(*, \"config_admin\")=List of 8 #>   ..$ schema_version: chr \"https://raw.githubusercontent.com/hubverse-org/schemas/main/v2.0.0/admin-schema.json\" #>   ..$ name          : chr \"Simple Forecast Hub\" #>   ..$ maintainer    : chr \"Consortium of Infectious Disease Modeling Hubs\" #>   ..$ contact       :List of 2 #>   .. ..$ name : chr \"Joe Bloggs\" #>   .. ..$ email: chr \"j.bloggs@cidmh.com\" #>   ..$ repository_url: chr \"https://github.com/hubverse-org/example-simple-forecast-hub\" #>   ..$ hub_models    :List of 1 #>   .. ..$ :List of 3 #>   .. .. ..$ team_abbr : chr \"simple_hub\" #>   .. .. ..$ model_abbr: chr \"baseline\" #>   .. .. ..$ model_type: chr \"baseline\" #>   ..$ file_format   : chr [1:3] \"csv\" \"parquet\" \"arrow\" #>   ..$ timezone      : chr \"US/Eastern\" #>   ..- attr(*, \"schema_id\")= chr \"https://raw.githubusercontent.com/hubverse-org/schemas/main/v2.0.0/admin-schema.json\" #>   ..- attr(*, \"type\")= chr \"admin\" #>   ..- attr(*, \"class\")= chr [1:2] \"config\" \"list\" #>  - attr(*, \"config_tasks\")=List of 2 #>   ..$ schema_version: chr \"https://raw.githubusercontent.com/hubverse-org/schemas/main/v2.0.0/tasks-schema.json\" #>   ..$ rounds        :List of 2 #>   .. ..$ :List of 4 #>   .. .. ..$ round_id_from_variable: logi TRUE #>   .. .. ..$ round_id              : chr \"origin_date\" #>   .. .. ..$ model_tasks           :List of 1 #>   .. .. .. ..$ :List of 3 #>   .. .. .. .. ..$ task_ids       :List of 4 #>   .. .. .. .. .. ..$ origin_date:List of 2 #>   .. .. .. .. .. .. ..$ required: NULL #>   .. .. .. .. .. .. ..$ optional: chr [1:2] \"2022-10-01\" \"2022-10-08\" #>   .. .. .. .. .. ..$ target     :List of 2 #>   .. .. .. .. .. .. ..$ required: chr \"wk inc flu hosp\" #>   .. .. .. .. .. .. ..$ optional: NULL #>   .. .. .. .. .. ..$ horizon    :List of 2 #>   .. .. .. .. .. .. ..$ required: int 1 #>   .. .. .. .. .. .. ..$ optional: int [1:3] 2 3 4 #>   .. .. .. .. .. ..$ location   :List of 2 #>   .. .. .. .. .. .. ..$ required: NULL #>   .. .. .. .. .. .. ..$ optional: chr [1:54] \"US\" \"01\" \"02\" \"04\" ... #>   .. .. .. .. ..$ output_type    :List of 2 #>   .. .. .. .. .. ..$ mean    :List of 2 #>   .. .. .. .. .. .. ..$ output_type_id:List of 2 #>   .. .. .. .. .. .. .. ..$ required: NULL #>   .. .. .. .. .. .. .. ..$ optional: logi NA #>   .. .. .. .. .. .. ..$ value         :List of 2 #>   .. .. .. .. .. .. .. ..$ type   : chr \"integer\" #>   .. .. .. .. .. .. .. ..$ minimum: int 0 #>   .. .. .. .. .. ..$ quantile:List of 2 #>   .. .. .. .. .. .. ..$ output_type_id:List of 2 #>   .. .. .. .. .. .. .. ..$ required: num [1:23] 0.01 0.025 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 ... #>   .. .. .. .. .. .. .. ..$ optional: NULL #>   .. .. .. .. .. .. ..$ value         :List of 2 #>   .. .. .. .. .. .. .. ..$ type   : chr \"integer\" #>   .. .. .. .. .. .. .. ..$ minimum: int 0 #>   .. .. .. .. ..$ target_metadata:List of 1 #>   .. .. .. .. .. ..$ :List of 7 #>   .. .. .. .. .. .. ..$ target_id    : chr \"wk inc flu hosp\" #>   .. .. .. .. .. .. ..$ target_name  : chr \"Weekly incident influenza hospitalizations\" #>   .. .. .. .. .. .. ..$ target_units : chr \"count\" #>   .. .. .. .. .. .. ..$ target_keys  :List of 1 #>   .. .. .. .. .. .. .. ..$ target: chr \"wk inc flu hosp\" #>   .. .. .. .. .. .. ..$ target_type  : chr \"continuous\" #>   .. .. .. .. .. .. ..$ is_step_ahead: logi TRUE #>   .. .. .. .. .. .. ..$ time_unit    : chr \"week\" #>   .. .. ..$ submissions_due       :List of 3 #>   .. .. .. ..$ relative_to: chr \"origin_date\" #>   .. .. .. ..$ start      : int -6 #>   .. .. .. ..$ end        : int 1 #>   .. ..$ :List of 4 #>   .. .. ..$ round_id_from_variable: logi TRUE #>   .. .. ..$ round_id              : chr \"origin_date\" #>   .. .. ..$ model_tasks           :List of 1 #>   .. .. .. ..$ :List of 3 #>   .. .. .. .. ..$ task_ids       :List of 5 #>   .. .. .. .. .. ..$ origin_date:List of 2 #>   .. .. .. .. .. .. ..$ required: NULL #>   .. .. .. .. .. .. ..$ optional: chr [1:3] \"2022-10-15\" \"2022-10-22\" \"2022-10-29\" #>   .. .. .. .. .. ..$ target     :List of 2 #>   .. .. .. .. .. .. ..$ required: chr \"wk inc flu hosp\" #>   .. .. .. .. .. .. ..$ optional: NULL #>   .. .. .. .. .. ..$ horizon    :List of 2 #>   .. .. .. .. .. .. ..$ required: int 1 #>   .. .. .. .. .. .. ..$ optional: int [1:3] 2 3 4 #>   .. .. .. .. .. ..$ location   :List of 2 #>   .. .. .. .. .. .. ..$ required: NULL #>   .. .. .. .. .. .. ..$ optional: chr [1:54] \"US\" \"01\" \"02\" \"04\" ... #>   .. .. .. .. .. ..$ age_group  :List of 2 #>   .. .. .. .. .. .. ..$ required: chr \"65+\" #>   .. .. .. .. .. .. ..$ optional: chr [1:4] \"0-5\" \"6-18\" \"19-24\" \"25-64\" #>   .. .. .. .. ..$ output_type    :List of 2 #>   .. .. .. .. .. ..$ mean    :List of 2 #>   .. .. .. .. .. .. ..$ output_type_id:List of 2 #>   .. .. .. .. .. .. .. ..$ required: NULL #>   .. .. .. .. .. .. .. ..$ optional: logi NA #>   .. .. .. .. .. .. ..$ value         :List of 2 #>   .. .. .. .. .. .. .. ..$ type   : chr \"integer\" #>   .. .. .. .. .. .. .. ..$ minimum: int 0 #>   .. .. .. .. .. ..$ quantile:List of 2 #>   .. .. .. .. .. .. ..$ output_type_id:List of 2 #>   .. .. .. .. .. .. .. ..$ required: num [1:23] 0.01 0.025 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 ... #>   .. .. .. .. .. .. .. ..$ optional: NULL #>   .. .. .. .. .. .. ..$ value         :List of 2 #>   .. .. .. .. .. .. .. ..$ type   : chr \"integer\" #>   .. .. .. .. .. .. .. ..$ minimum: int 0 #>   .. .. .. .. ..$ target_metadata:List of 1 #>   .. .. .. .. .. ..$ :List of 7 #>   .. .. .. .. .. .. ..$ target_id    : chr \"wk inc flu hosp\" #>   .. .. .. .. .. .. ..$ target_name  : chr \"Weekly incident influenza hospitalizations\" #>   .. .. .. .. .. .. ..$ target_units : chr \"count\" #>   .. .. .. .. .. .. ..$ target_keys  :List of 1 #>   .. .. .. .. .. .. .. ..$ target: chr \"wk inc flu hosp\" #>   .. .. .. .. .. .. ..$ target_type  : chr \"continuous\" #>   .. .. .. .. .. .. ..$ is_step_ahead: logi TRUE #>   .. .. .. .. .. .. ..$ time_unit    : chr \"week\" #>   .. .. ..$ submissions_due       :List of 3 #>   .. .. .. ..$ relative_to: chr \"origin_date\" #>   .. .. .. ..$ start      : int -6 #>   .. .. .. ..$ end        : int 1 #>   ..- attr(*, \"schema_id\")= chr \"https://raw.githubusercontent.com/hubverse-org/schemas/main/v2.0.0/tasks-schema.json\" #>   ..- attr(*, \"type\")= chr \"tasks\" #>   ..- attr(*, \"class\")= chr [1:2] \"config\" \"list\" mod_out_path <- system.file(\"testhubs/simple/model-output\", package = \"hubUtils\") mod_out_con <- connect_model_output(mod_out_path) print(mod_out_con) #>  #> ── <mod_out_connection/FileSystemDataset> ── #>  #> • file_format: \"csv(3/3)\" #> • checks: TRUE #> • file_system: \"LocalFileSystem\" #> • model_output_dir: #>   \"/home/runner/work/_temp/Library/hubUtils/testhubs/simple/model-output\" #>  #> ── Connection schema  #> mod_out_connection with 3 csv files #> 8 columns #> origin_date: date32[day] #> target: string #> horizon: int64 #> location: string #> output_type: string #> output_type_id: double #> value: int64 #> model_id: string"},{"path":"https://hubverse-org.github.io/hubData/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. hubUtils as_model_out_tbl, model_id_merge, model_id_split, validate_model_out_tbl","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/s3_bucket.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to an AWS S3 bucket — s3_bucket","title":"Connect to an AWS S3 bucket — s3_bucket","text":"See arrow::s3_bucket() details.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/s3_bucket.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect to an AWS S3 bucket — s3_bucket","text":"SubTreeFileSystem containing S3FileSystem bucket's relative path. Note function's success guarantee authorized access bucket's contents.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/reference/s3_bucket.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Connect to an AWS S3 bucket — s3_bucket","text":"","code":"if (FALSE) { bucket <- s3_bucket(\"voltrondata-labs-datasets\") } if (FALSE) { # Turn on debug logging. The following line of code should be run in a fresh # R session prior to any calls to `s3_bucket()` (or other S3 functions) Sys.setenv(\"ARROW_S3_LOG_LEVEL\"=\"DEBUG\") bucket <- s3_bucket(\"voltrondata-labs-datasets\") }"},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-development-version","dir":"Changelog","previous_headings":"","what":"hubData (development version)","title":"hubData (development version)","text":"as_r_schema(): Converts Arrow schema named character vector equivalent R types (e.g., \"int32\" → \"integer\"). Errors unsupported types. arrow_schema_to_string(): Extracts raw Arrow type strings field schema. is_supported_arrow_type(): Returns named logical vector indicating schema fields supported types. validate_arrow_schema(): Validates field types Arrow schema supported. Throws helpful error otherwise. Added arrow_to_r_datatypes, named character vector defining mapping safe portable Arrow types R equivalents. Added r_schema argument create_timeseries_schema() create_oracle_output_schema() functions enable returning schema vector R data types instead arrow::Schema object (#95) Added output_type_id_datatype argument create_oracle_output_schema() connect_target_oracle_output() functions allow users explicitly specify data type output_type_id column schema. ensuring compatibility create_hub_schema() connect_hub() (#95).","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-140","dir":"Changelog","previous_headings":"","what":"hubData 1.4.0","title":"hubData 1.4.0","text":"Added connect_target_timeseries() function (experimental) accessing time-series target data hub (#71). includes accessing target data cloud hubs (#75). Added create_timeseries_schema() function creating schema time-series target data (#71). Added connect_target_oracle_output() function (experimental) accessing oracle-output target data hub (#72). includes accessing target data cloud hubs (#76). Added create_oracle_output_schema() function creating schema oracle-output target data (#72). Added get_target_path() function retrieving path appropriate target data file directory hub. Added get_target_file_ext() function retrieving file extensions target data file(s) hub. Added get_s3_bucket_name() extracting bucket name cloud enabled hub hub’s config (#75). Added na argument connect_hub(), connect_model_output(), connect_target_timeseries(), connect_target_oracle_output(), create_timeseries_schema(), create_oracle_output_schema() allow specification handle missing values CSV files. default use NA \"\", users can restrict \"\" (empty string) needing include character \"NA\" values CSV data (#80). Note approach works NA values written CSV file \"\" (empty string) NA \"NA\". Added ignore_files argument connect_hub() connect_model_output() allow users specify vector file name prefixes ignore scanning hub’s model output directory files. useful excluding files relevant hub’s model output, README files documentation well potentially invalid files (#87). feature also used internally connect_hub() enable skipping expensive file validity checks connecting cloud-based hubs multiple file formats using skip_checks = TRUE. Refactored connect_hub() connect_model_output() internally reduce number calls cloud hubs, improving performance connecting cloud-based hubs. Added ignore_files argument connect_target_oracle_output(), connect_target_timeseries(), create_timeseries_schema(), create_oracle_output_schema() allow users specify vector file name prefixes ignore scanning hub’s target data directory files (#87).","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-130","dir":"Changelog","previous_headings":"","what":"hubData 1.3.0","title":"hubData 1.3.0","text":"Support determination hub schema v4 configuration files (#63). Also fixes bug create_hub_schema() output_type_id data type incorrectly auto-determined logical point estimate output types collected hub. Now character data type returned output_type_id schema versions situations auto-determined.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-123","dir":"Changelog","previous_headings":"","what":"hubData 1.2.3","title":"hubData 1.2.3","text":"Fix bug create_hub_schema() output_type_id data type incorrectly determined Date instead character (Reported https://github.com/reichlab/variant-nowcast-hub/pull/87#issuecomment-2387372238).","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-122","dir":"Changelog","previous_headings":"","what":"hubData 1.2.2","title":"hubData 1.2.2","text":"Remove dependency development version arrow package bump required version 17.0.0.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-121","dir":"Changelog","previous_headings":"","what":"hubData 1.2.1","title":"hubData 1.2.1","text":"Removed dependency development version zoltr package. Fixed minor error connect_hub() article.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-120","dir":"Changelog","previous_headings":"","what":"hubData 1.2.0","title":"hubData 1.2.0","text":"model output directory contains model output data (README.md, example) model output files use single file format.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-111","dir":"Changelog","previous_headings":"","what":"hubData 1.1.1","title":"hubData 1.1.1","text":"Fix {tidyselect} warnings converting internal syntax Bump required dplyr version 1.1.0","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-110","dir":"Changelog","previous_headings":"","what":"hubData 1.1.0","title":"hubData 1.1.0","text":"Add \"from_config\" option output_type_id_datatype argument create_hub_schema(), coerce_to_hub_schema() connect_hub(). allows users set hub level output_type_id column data type tasks.json output_type_id_datatype property introduced schema version v3.0.1. (#44)","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-100","dir":"Changelog","previous_headings":"","what":"hubData 1.0.0","title":"hubData 1.0.0","text":"Breaking change: expand_model_out_val_grid() create_model_out_submit_tmpl() now defunct. functions moved hubValidations replaced hubValidations::expand_model_out_grid() hubValidations::submission_tmpl(), respectively. old functions now fail called removed future release.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-020","dir":"Changelog","previous_headings":"","what":"hubData 0.2.0","title":"hubData 0.2.0","text":"Adds back-compatible support create_hub_schema() determining hub’s schema v3.0.0 sample output type configurations tasks.json files (#27). Adds back-compatible support v3.0.0 sample output type configuration tasks.json files. primary change output_type_id values sample output types handled expand_model_out_val_grid(). default, valid task ID value combinations expanded, per output type, NAs returned output_type_id column. However, new argument include_sample_ids set TRUE, example sample IDs included output_type_id column, demonstrating compound tasks IDs group rows task ID combinations samples. unique across modeling tasks. create_model_out_submit_tmpl(), example sample IDs included output_type_id column default (#30).","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-011","dir":"Changelog","previous_headings":"","what":"hubData 0.1.1","title":"hubData 0.1.1","text":"Add collect_zoltar(), retrieves data zoltardata.com project transforms Zoltar’s native download format hubverse one. Zoltar (documentation ) pre-hubverse research project implements repository model forecast results, including tools administer, query, visualize uploaded data, along R Python APIs access data programmatically (zoltr zoltpy, respectively.)","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-010","dir":"Changelog","previous_headings":"","what":"hubData 0.1.0","title":"hubData 0.1.0","text":"Add collect_hub() wraps dplyr::collect() , possible, converts output model_out_tbl class object default. function also accepts additional arguments can passed as_model_out_tbl(). Allow parsing tasks.json config files required optional properties task IDs set null. change facilitates encoding task IDs modeling tasks value expected given task ID. model output files, value modeling task task IDs NA.","code":""},{"path":"https://hubverse-org.github.io/hubData/dev/news/index.html","id":"hubdata-001","dir":"Changelog","previous_headings":"","what":"hubData 0.0.1","title":"hubData 0.0.1","text":"Initial package release resulting split hubUtils package. See hubUtils NEWS.md details including previous release notes.","code":""}]
